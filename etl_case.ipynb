{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b00eedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, regexp_replace\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Iniciar uma sessão no Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL Task With Delta Lake\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8d13e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Filtrar os dados com respostas válidas\n",
    "    filtered_data = df.filter((col(\"Respondent\").isNotNull()) & (col(\"Salary\").isNotNull()) &\n",
    "                              (col(\"YearsCoding\").isNotNull()) & (col(\"YearsCoding\").isNotNull()))\n",
    "\n",
    "    # Remover registros duplicados com base no campo \"Respondent\"\n",
    "    filtered_data = filtered_data.dropDuplicates(['Respondent'])\n",
    "\n",
    "    # Tratar os valores em branco\n",
    "    filtered_data = filtered_data.withColumn(\"Student\", when(col(\"Student\").isNull(), \"NO\").otherwise(col(\"Student\")))\n",
    "    filtered_data = filtered_data.withColumn(\"Employment\", when(col(\"Employment\").isNull(), \"Full-time\").otherwise(col(\"Employment\")))\n",
    "\n",
    "    # Remover registros com mais de 3 campos vazios\n",
    "    filtered_data = filtered_data.withColumn(\"EmptyFieldsCount\",\n",
    "                                             (col(\"Student\").isNull().cast(\"integer\") +\n",
    "                                              col(\"Employment\").isNull().cast(\"integer\") +\n",
    "                                              col(\"Salary\").isNull().cast(\"integer\") +\n",
    "                                              col(\"YearsCoding\").isNull().cast(\"integer\")))\n",
    "    filtered_data = filtered_data.filter(col(\"EmptyFieldsCount\") <= 3).drop(\"EmptyFieldsCount\")\n",
    "\n",
    "    # Tratar o formato dos valores de salário\n",
    "    filtered_data = filtered_data.withColumn(\"Salary\", regexp_replace(col(\"Salary\"), \"[^0-9.]\", \"\").cast(\"float\"))\n",
    "\n",
    "    # Converter salários para base anual\n",
    "    filtered_data = filtered_data.withColumn(\"Salary\", when(col(\"SalaryType\") == \"Monthly\", col(\"Salary\") * 12)\n",
    "                                             .when(col(\"SalaryType\") == \"Weekly\", col(\"Salary\") * 52)\n",
    "                                             .otherwise(col(\"Salary\")))\n",
    "\n",
    "    # Corrigir a codificação dos caracteres\n",
    "    filtered_data = filtered_data.withColumn(\"Country\", regexp_replace(col(\"Country\"), \"[^\\x00-\\x7F]+\", \"\"))\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43bad33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Registros no DF raw_data antes do Pré-processamento: 10000\n",
      "Total de Registros no DF raw_data_updates antes do Pré-processamento: 10003\n",
      "Total de Registros no DF raw_data após o Pré-processamento: 7405\n",
      "Total de Registros no DF raw_data_updates após o Pré-processamento: 7408\n"
     ]
    }
   ],
   "source": [
    "# Carregar os dados dos arquivos CSV\n",
    "raw_data = spark.read.csv(\"data/RawData.csv\", header=True, inferSchema=True)\n",
    "raw_data_updates = spark.read.csv(\"data/RawDataUpdates.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Count de Registros antes do Pré-processamento\n",
    "print(f\"Total de Registros no DF raw_data antes do Pré-processamento: {raw_data.count()}\")\n",
    "print(f\"Total de Registros no DF raw_data_updates antes do Pré-processamento: {raw_data_updates.count()}\")\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "filtered_data = preprocess_data(raw_data)\n",
    "filtered_data_updates = preprocess_data(raw_data_updates)\n",
    "\n",
    "# Count de Registros após o Pré-processamento\n",
    "print(f\"Total de Registros no DF raw_data após o Pré-processamento: {filtered_data.count()}\")\n",
    "print(f\"Total de Registros no DF raw_data_updates após o Pré-processamento: {filtered_data_updates.count()}\")\n",
    "\n",
    "# Selecionar os campos necessários para o esquema final\n",
    "final_data = filtered_data.select(\"Respondent\", \"Salary\", \"YearsCoding\", \"YearsCodingProf\", \"Student\", \"Employment\",\n",
    "                                  \"Country\", \"FormalEducation\", \"CurrencySymbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33f55a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count antes do merge: 7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count após o merge: 7408\n",
      "Esquema da tabela Delta final:\n",
      "root\n",
      " |-- Respondent: integer (nullable = true)\n",
      " |-- Salary: float (nullable = true)\n",
      " |-- YearsCoding: string (nullable = true)\n",
      " |-- YearsCodingProf: string (nullable = true)\n",
      " |-- Student: string (nullable = true)\n",
      " |-- Employment: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- FormalEducation: string (nullable = true)\n",
      " |-- CurrencySymbol: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Caminho para o diretório de saída do Delta Lake\n",
    "delta_path = \"delta_output\"\n",
    "\n",
    "# Verificar se a tabela Delta já existe\n",
    "if DeltaTable.isDeltaTable(spark, delta_path):\n",
    "    # Carregar a tabela Delta existente\n",
    "    delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "else:\n",
    "    # Salvar o DataFrame final em formato Delta Lake\n",
    "    final_data.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
    "    # Inicializar a tabela Delta\n",
    "    delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "\n",
    "# Imprimir o count da tabela Delta antes do merge\n",
    "print(f\"Count antes do merge: {delta_table.toDF().count()}\")\n",
    "\n",
    "# Definir a condição de merge\n",
    "condition = \"target.Respondent = source.Respondent\"\n",
    "\n",
    "# Definir as ações de atualização e inserção\n",
    "update_action = {\n",
    "    \"Salary\": \"source.Salary\"\n",
    "}\n",
    "\n",
    "insert_action = {\n",
    "    \"Respondent\": \"source.Respondent\",\n",
    "    \"Salary\": \"source.Salary\",\n",
    "    \"YearsCoding\": \"source.YearsCoding\",\n",
    "    \"YearsCodingProf\": \"source.YearsCodingProf\",\n",
    "    \"Student\": \"source.Student\",\n",
    "    \"Employment\": \"source.Employment\",\n",
    "    \"Country\": \"source.Country\",\n",
    "    \"FormalEducation\": \"source.FormalEducation\",\n",
    "    \"CurrencySymbol\": \"source.CurrencySymbol\"\n",
    "}\n",
    "\n",
    "# Executar a operação de merge\n",
    "delta_table.alias(\"target\") \\\n",
    "    .merge(filtered_data_updates.alias(\"source\"), condition) \\\n",
    "    .whenMatchedUpdate(condition=condition, set=update_action) \\\n",
    "    .whenNotMatchedInsert(values=insert_action) \\\n",
    "    .execute()\n",
    "\n",
    "# Imprimir o count da tabela Delta após o merge\n",
    "print(f\"Count após o merge: {delta_table.toDF().count()}\")\n",
    "\n",
    "# Imprimir o esquema da tabela Delta final\n",
    "print(\"Esquema da tabela Delta final:\")\n",
    "delta_table.toDF().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9948968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizar a sessão Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
